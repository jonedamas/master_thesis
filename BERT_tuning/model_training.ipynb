{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, Trainer, BertForSequenceClassification, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# do a confusion matrix\n",
    "\n",
    "\n",
    "print(torch.__version__, ' ', transformers.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# load FinBERT\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'yiyanghkust/finbert-pretrain', \n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'yiyanghkust/finbert-pretrain'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment mapping\n",
    "- positive: 1 -> low risk\n",
    "- neutral: 2 -> medium risk\n",
    "- negative: 0 -> high risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labeled_headlines_specific.csv')\n",
    "df.columns = ['sentence', 'label'] ## use your own customized dataset\n",
    "df.head()\n",
    "\n",
    "df = df.dropna(subset=['sentence', 'label'])\n",
    "\n",
    "df_train, df_test, = train_test_split(df, stratify=df['label'], test_size=0.25, random_state=42)\n",
    "df_train, df_val = train_test_split(df_train, stratify=df_train['label'],test_size=0.25, random_state=42)\n",
    "\n",
    "print(df_train.shape, df_test.shape, df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_test_val = {'train':df_train, 'test':df_test, 'val':df_val}\n",
    "dataset_dict = {}\n",
    "\n",
    "for tag, dataset in train_test_val.items():\n",
    "    \n",
    "    data = Dataset.from_pandas(dataset).map(\n",
    "        lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length', max_length=128), \n",
    "        batched=True\n",
    "        )\n",
    "    data.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "    dataset_dict[tag] = data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy' : accuracy_score(predictions, labels)}\n",
    "\n",
    "args = TrainingArguments(\n",
    "        output_dir = 'temp/',\n",
    "        evaluation_strategy = 'epoch',\n",
    "        save_strategy = 'epoch',\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='accuracy',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "        args=args,                           # training arguments, defined above\n",
    "        train_dataset=dataset_dict['train'],         # training dataset\n",
    "        eval_dataset=dataset_dict['val'],            # evaluation dataset\n",
    "        compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "prediction_output = trainer.predict(dataset_dict['test'])\n",
    "\n",
    "print(prediction_output.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "predictions = np.argmax(prediction_output.predictions, axis=1)\n",
    "\n",
    "print(classification_report(dataset_dict['test']['label'], predictions))\n",
    "\n",
    "labels = prediction_output.label_ids\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xticks(ticks=[0.5, 1.5, 2.5], labels=['Negative', 'Positive', 'Neutral'])\n",
    "plt.yticks(ticks=[0.5, 1.5, 2.5], labels=['Negative', 'Positive', 'Neutral'])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('models/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
