{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tsa.api import SVAR, VAR\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "REPO_PATH = os.getenv(\"REPO_PATH\")\n",
    "\n",
    "# Import main utility functions\n",
    "sys.path.insert(0, rf'{REPO_PATH}src_HF')\n",
    "from utils.main_utils import combload_topic_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = ['CRU', 'CWP', 'CEN']\n",
    "FUTURES = ['LCOc1', 'CLc1']\n",
    "\n",
    "news_df = combload_topic_dfs(\n",
    "    TOPICS, \n",
    "    lambda topic: rf'{REPO_PATH}data\\sentiment_data\\{topic}_ARTICLE_SENTIMENT.csv'\n",
    ")\n",
    "news_df.index = pd.to_datetime(news_df.index)\n",
    "\n",
    "display(news_df.head(2))\n",
    "\n",
    "\n",
    "futures_dfs = {\n",
    "    future: pd.read_csv(\n",
    "        rf'{REPO_PATH}data\\time_series\\{future}_5min_processed.csv', \n",
    "        index_col=0\n",
    "    ) for future in FUTURES\n",
    "}\n",
    "\n",
    "for price_df in futures_dfs.values():\n",
    "    price_df.index = pd.to_datetime(price_df.index)\n",
    "    price_df['REALIZED_VOL'] = price_df['REALIZED_VOL'] * 12 * 252 * 24\n",
    "    price_df['LOGRET'] = price_df['LOGRET'] * 12 * 24\n",
    "\n",
    "RESAMPLE_WINDOW: str = '5min'\n",
    "\n",
    "SENTIMENT_COLUMNS: list[str] = [\n",
    "    'TextBlob_headline', \n",
    "    'VADER_headline', \n",
    "    'TextBlob_fullStory', \n",
    "    'VADER_fullStory'\n",
    "]\n",
    "\n",
    "resample_dfs = {\n",
    "    topic: pd.DataFrame(\n",
    "        {\n",
    "            col: news_df[col].resample(RESAMPLE_WINDOW).mean() for col in SENTIMENT_COLUMNS\n",
    "        }\n",
    "    ).fillna(0) for topic in TOPICS\n",
    "}\n",
    "\n",
    "for res_df in resample_dfs.values():\n",
    "    count_df = news_df.copy()\n",
    "    count_df['article_count'] = 1\n",
    "    res_df['article_count'] = count_df['article_count'].resample(RESAMPLE_WINDOW).sum()\n",
    "\n",
    "combined_dfs = {\n",
    "    future: {\n",
    "        topic: resample_dfs[topic].join(futures_dfs[future]).dropna() for topic in TOPICS\n",
    "    } for future in FUTURES\n",
    "}\n",
    "\n",
    "display(combined_dfs['LCOc1']['CEN'].head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUMENT = 'LCOc1'\n",
    "TOPIC = 'CEN'\n",
    "\n",
    "df = combined_dfs[INSTRUMENT][TOPIC]\n",
    "\n",
    "variables = SENTIMENT_COLUMNS + ['article_count', 'CLOSE', 'VOLUME', 'COUNT', 'REALIZED_VOL']\n",
    "\n",
    "results = {}\n",
    "for col in tqdm(variables):\n",
    "    result = adfuller(df[col])\n",
    "    results[col] = result[:2]\n",
    "\n",
    "res_df = pd.DataFrame(results).T\n",
    "res_df.columns = ['ADF Statistic', 'p-value']\n",
    "\n",
    "print(f'ADFuller test results for {INSTRUMENT} and {TOPIC} sentiment data:')\n",
    "display(res_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAR Optmal lag order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal lag order\n",
    "INSTRUMENT = 'LCOc1'\n",
    "RESPONSE: list[str] = ['VOLUME', 'REALIZED_VOL', 'article_count']\n",
    "SENTIMENT_COLUMNS: list[str] = ['TextBlob_headline', 'VADER_headline', 'TextBlob_fullStory', 'VADER_fullStory']\n",
    "\n",
    "colors = ['crimson', 'navy', 'limegreen']\n",
    "\n",
    "def plot_criterion(lag_orders, ax, name):\n",
    "    for k, ic in enumerate(['aic', 'bic', 'hqic']):\n",
    "        ic_info = lag_orders.ics[ic]\n",
    "        lags = range(len(ic_info))\n",
    "        ax.plot(lags, ic_info, label=ic.upper(), color=colors[k], lw=0.8)\n",
    "        \n",
    "        min_ic = np.argmin(ic_info)\n",
    "        ax.plot(min_ic, ic_info[min_ic], 'ro', color=colors[k])\n",
    "        # annotate the min point\n",
    "        ax.annotate(\n",
    "            f'{min_ic}', (min_ic, ic_info[min_ic]), \n",
    "            textcoords=\"offset points\", xytext=(0, 10), \n",
    "            ha='center', fontsize=10\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel('Lag order')\n",
    "    ax.legend(frameon=False, loc='upper right', title=name, fontsize=10)    \n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4), dpi=200)\n",
    "\n",
    "for i, topic in tqdm(enumerate(TOPICS)):\n",
    "    df = combined_dfs[INSTRUMENT][topic]\n",
    "    model = VAR(df[[*RESPONSE, *SENTIMENT_COLUMNS]])\n",
    "    lag_order = model.select_order(30, trend='c')\n",
    "    plot_criterion(lag_order, ax[i], topic)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(rf'images/lag_order_{INSTRUMENT}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Granger causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_combined[[*SENTIMENT_COLUMNS, *RESPONSE]]\n",
    "\n",
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False, maxlag=12):    \n",
    "   \n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df\n",
    "\n",
    "grangers_causation_matrix(df, df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE: list[str] = ['VOLUME', 'REALIZED_VOL']\n",
    "SENTIMENT_COLUMNS: list[str] = ['TextBlob_headline', 'VADER_headline', 'TextBlob_fullStory', 'VADER_fullStory']\n",
    "\n",
    "def plot_response(df: pd.DataFrame, response: list[str], sentiment: list[str], response_names: list[str], sentiment_names: list[str]) -> plt.Figure:\n",
    "\n",
    "    colors_pos = ['tab:blue', 'gray', 'gray']\n",
    "    colors_neg = ['tab:red', 'gray', 'gray']\n",
    "    linestyles = ['-', '--', '--']\n",
    "\n",
    "    figure, axs = plt.subplots(\n",
    "        len(response), \n",
    "        len(sentiment), \n",
    "        figsize=(4 * len(sentiment), 4 * len(response))\n",
    "    )\n",
    "\n",
    "    df_pos = df.copy()\n",
    "    df_pos[SENTIMENT_COLUMNS] = df_pos[SENTIMENT_COLUMNS].clip(lower=0)\n",
    "    df_neg = df.copy()\n",
    "    df_neg[SENTIMENT_COLUMNS] = df_neg[SENTIMENT_COLUMNS].clip(upper=0).abs()\n",
    "\n",
    "    for j, sent_col in enumerate(sentiment):\n",
    "        model_pos: VAR = VAR(df_pos[[sent_col, *response]])\n",
    "        model_neg: VAR = VAR(df_neg[[sent_col, *response]])\n",
    "\n",
    "        results_pos = model_pos.fit(5)\n",
    "        results_neg = model_neg.fit(5)\n",
    "\n",
    "        # impulse response\n",
    "        irf_pos = results_pos.irf(12)\n",
    "        irf_neg = results_neg.irf(12)\n",
    "        fig = irf_pos.plot(orth=False, impulse=sent_col)\n",
    "        fig_neg = irf_neg.plot(orth=False, impulse=sent_col)\n",
    "\n",
    "        for i, (ax, ax_neg) in enumerate(zip(fig.axes[1:], fig_neg.axes[1:])):\n",
    "\n",
    "            for k in range(3):\n",
    "                axs[i, j].plot(\n",
    "                    ax.lines[k].get_xdata(), ax.lines[k].get_ydata(), \n",
    "                    linestyle=linestyles[k], \n",
    "                    color=colors_pos[k], \n",
    "                    label=f'Positive sentiment' if k == 0 else None\n",
    "                )\n",
    "                axs[i, j].plot(\n",
    "                    ax_neg.lines[k].get_xdata(), ax_neg.lines[k].get_ydata(), \n",
    "                    linestyle=linestyles[k], \n",
    "                    color=colors_neg[k], \n",
    "                    label=f'Negative sentiment' if k == 0 else None\n",
    "                )\n",
    "            axs[i, j].set_title(fr'{sentiment_names[j]} $\\rightarrow$ {response_names[i]}', fontsize=15)\n",
    "            axs[i, j].axhline(0, color='black', lw=0.5)\n",
    "            axs[i, j].set_xlabel('Minutes', fontsize=14)\n",
    "            axs[i, j].set_ylabel(response_names[i] + ' response', fontsize=14)\n",
    "            axs[i, j].legend(fontsize=11, frameon=False, loc='upper right')\n",
    "\n",
    "            # multiply x-ticks with 5 \n",
    "            axs[i, j].set_xticks(np.arange(0, 13, 2))\n",
    "            axs[i, j].set_xticklabels(np.arange(0, 13, 2) * 5)\n",
    "\n",
    "    figure.tight_layout(pad=1.0)\n",
    "\n",
    "    return figure\n",
    "\n",
    "\n",
    "fig = plot_response(df_combined, RESPONSE, SENTIMENT_COLUMNS, ['Volume', 'RV'], SENTIMENT_COLUMNS)\n",
    "\n",
    "fig.savefig(rf'VAR_IRF.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impulse response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.impulse_responses(10, orthogonalized=True, impulse=[1, 0]).plot(figsize=(13,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
