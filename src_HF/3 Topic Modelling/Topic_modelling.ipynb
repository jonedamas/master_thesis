{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "pyLDAvis.enable_notebook()\n",
    "REPO_PATH =  os.getenv('REPO_PATH')\n",
    "\n",
    "sys.path.insert(0, rf'{REPO_PATH}src_HF')\n",
    "from utils.text_utils import clean_token_series, IGNORE_WORDS\n",
    "from utils.topic_utils import classify_article, LDAModelSetup\n",
    "from utils.main_utils import combload_topic_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS: list[str] = ['CRU', 'CWP', 'CEN']\n",
    "\n",
    "text_df = combload_topic_dfs(\n",
    "    TOPICS, \n",
    "    lambda topic: rf'{REPO_PATH}data\\news_data\\EIKON_{topic}_NEWS_COMPLETE.json'\n",
    ")\n",
    "\n",
    "text_df['cleaned_tokenized'] = clean_token_series(text_df['fullStory'])\n",
    "\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_params = {\n",
    "    'num_topics': 3,\n",
    "    'chunksize': 500,\n",
    "    'passes': 20,\n",
    "    'iterations': 100,\n",
    "    'eval_every': 1\n",
    "}\n",
    "\n",
    "models = {}\n",
    "for topic in TOPICS:\n",
    "    print(f'Creating model for {topic}...')\n",
    "    model = LDAModelSetup(\n",
    "        text_df.loc[text_df['topic'] == topic, 'cleaned_tokenized'],\n",
    "        name=topic,\n",
    "        stopwords=IGNORE_WORDS, \n",
    "        lda_params=lda_params\n",
    "    ).create_model()\n",
    "\n",
    "    models[topic] = model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDAvis visualization of gensim LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = 'CRU'\n",
    "\n",
    "display(models[TOPIC].visfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(21, 7), dpi=200)\n",
    "\n",
    "for i, topic in enumerate(TOPICS):\n",
    "    LDA_fig = models[topic].plot_pyLDAvis()\n",
    "    axs[i].imshow(LDA_fig)\n",
    "\n",
    "fig.savefig(rf'images\\pyLDAvis_topic_PC.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign topics to each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in TOPICS:\n",
    "    df = text_df[text_df['topic'] == topic]\n",
    "    df['topic'] = df.apply(\n",
    "        lambda x: classify_article(\n",
    "            x, \n",
    "            models[topic].dictionary, \n",
    "            models[topic].model\n",
    "        ), axis=1\n",
    "    )\n",
    "    topic_dict = dict(zip(df['storyId'], df['topic']))\n",
    "\n",
    "    with open(rf'{REPO_PATH}data\\topics\\{topic}_TOPICS.json', 'w') as f:\n",
    "        json.dump(topic_dict, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
