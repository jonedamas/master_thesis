{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sent_utils import * # has to be first to avoid conflict with Julia load\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from arch import arch_model\n",
    "import scienceplots\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "repo_path = os.getenv(\"REPO_PATH\")\n",
    "plt.style.use('science')\n",
    "\n",
    "# Import main utility functions\n",
    "sys.path.insert(0, repo_path + r'src_HF')\n",
    "\n",
    "from utils.main_utils import *\n",
    "from utils.text_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Testing\n",
    "\n",
    "Sentiment analysis functions should take a panads series as input and output a pandas series of the same length with the sentiment of the input text. The sentiment should be a float between -1 and 1, where -1 is negative, 0 is neutral, and 1 is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'CRU'\n",
    "\n",
    "# Load data from database\n",
    "text_df = pd.read_json(repo_path + rf'data\\news_data\\EIKON_{topic}_NEWS_COMPLETE.json', lines=True, orient='records')\n",
    "\n",
    "display(text_df.head(2))\n",
    "print(text_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis with Textblob and VADER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['TextBlob_headline'] = add_textblob_polarity(text_df['text'])\n",
    "text_df['VADER_headline'] = add_vader_compound(text_df['text'])\n",
    "\n",
    "text_df['TextBlob_fullStory'] = add_textblob_polarity(text_df['fullStory'])\n",
    "text_df['VADER_fullStory'] = add_vader_compound(text_df['fullStory'])\n",
    "\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop text columns for storage efficiency\n",
    "text_df.drop(columns=['text', 'fullStory'], inplace=True)\n",
    "\n",
    "text_df.to_csv(repo_path + rf'data\\sentiment_data\\{topic}_ARTICLE_SENTIMENT.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between Textblob and VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "text_df.plot.scatter(x='TextBlob_headline', y='TextBlob_fullStory', alpha=0.5, ax=axs[0, 0], s=3)\n",
    "text_df.plot.scatter(x='VADER_headline', y='VADER_fullStory', alpha=0.5, ax=axs[1, 0], s=3)\n",
    "\n",
    "text_df.plot.scatter(x='TextBlob_headline', y='VADER_headline', alpha=0.5, ax=axs[0, 1], s=3)\n",
    "text_df.plot.scatter(x='TextBlob_fullStory', y='VADER_fullStory', alpha=0.5, ax=axs[1, 1], s=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_df.plot.scatter(x='TextBlob', y='VADER', alpha=0.5, s=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "text_df['TextBlob'].plot.hist(bins=100, alpha=0.5, label='TextBlob', ax=ax)\n",
    "text_df['VADER'].plot.hist(bins=100, alpha=0.5, label='VADER', ax=ax)\n",
    "\n",
    "text_df['compound'] = text_df['VADER'] * 0.5 + text_df['TextBlob'] * 0.5\n",
    "\n",
    "text_df['compound'].plot.hist(bins=100, alpha=0.5, label='compound', ax=ax)\n",
    "\n",
    "ax.legend(fontsize=14)\n",
    "ax.set_xlabel('Sentiment score', fontsize=14)\n",
    "ax.set_ylabel('Frequency', fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "fig.savefig(repo_path + r'src_HF\\3 Sentiment Analysis\\images', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter filename here:\n",
    "file_name = f'SENTIMENT_ALL_NEWS.csv'\n",
    "# Enter relative path for saving the file:\n",
    "relative_path = 'data/news'\n",
    "\n",
    "sentiment_df.to_csv(save_path(relative_path, file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation and Sentiment index\n",
    "\n",
    "Calculates the daily average sentiment score.\n",
    "```python \n",
    "aggregate_score()\n",
    "``` \n",
    "$$\n",
    "SV_t = \\frac{1}{N_t}\\sum_{i=1}^{n} PV_{it}\n",
    "$$\n",
    "\n",
    "Calculates the close sentiment and applying it to the first day market is open.\n",
    "```python \n",
    "merge_sentiment()\n",
    "```\n",
    "$$\n",
    "SV_{t,new} =\\frac{\\sum_{k=0}^{K}0.9^k\\cdot SV_{t-k}}{\\sum_{k=0}^{K}0.9^k}\n",
    "$$\n",
    "\n",
    "Creates a sentiment index.\n",
    "```python \n",
    "SI_bai()\n",
    "``` \n",
    "\n",
    "$$\n",
    "SI_t = SV_t+ \\sum_{i=1}^{t-1} SV_i\\cdot e^{-\\frac{t-1}{\\beta}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate to daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data\n",
    "sample_freq = 'h'\n",
    "\n",
    "sentiment_df.index = pd.to_datetime(sentiment_df['versionCreated'])\n",
    "\n",
    "df_sent = aggregate_score(sentiment_df, ['polarity', 'subjectivity'], frequency=sample_freq)\n",
    "\n",
    "display(df_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = pd.read_csv(r'C:\\Users\\joneh\\master_thesis\\data\\time_series\\CLc1_High_Frequency.csv')\n",
    "price_df.index = pd.to_datetime(price_df['Date']).dt.tz_localize(None)\n",
    "\n",
    "df_sent.index = df_sent.index.tz_localize(None)\n",
    "\n",
    "# calculate log-returns\n",
    "price_df['LOGRET'] = np.log(price_df['CLOSE']).diff()\n",
    "\n",
    "# add GARCH(1,1) model\n",
    "garch = arch_model(price_df['LOGRET'].dropna(), vol='Garch', p=1, q=1)\n",
    "res = garch.fit(disp='off')\n",
    "price_df['GARCH'] = res.conditional_volatility\n",
    "\n",
    "combined_df = df_sent.join(\n",
    "    price_df[['GARCH', 'CLOSE', 'LOGRET', 'VOLUME']], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "combined_df = combined_df.dropna()\n",
    "\n",
    "display(combined_df)\n",
    "\n",
    "# add sentiment index\n",
    "combined_df['SI_BAI'] = SI_bai(combined_df['polarity'], beta=7)\n",
    "\n",
    "x_label = 'count'\n",
    "y_label = 'GARCH'\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(combined_df[x_label], combined_df[y_label])\n",
    "print(f'p-value: {p_value:.10f}')\n",
    "print(f'R2: {r_value:.4f}')\n",
    "print(f'Slope: {slope:.4f}')\n",
    "print(f'Correlation: {combined_df[x_label].corr(combined_df[y_label]):.4f}')\n",
    "\n",
    "fig = sns.jointplot(\n",
    "    data=combined_df, \n",
    "    x=x_label, \n",
    "    y=y_label,\n",
    "    scatter_kws={'s':5},\n",
    "    kind='reg',\n",
    "    line_kws={'color':'red'},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save sentiment indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter filename here:\n",
    "file_name = 'sentiment_index.csv'\n",
    "# Enter relative path for saving the file:\n",
    "relative_path = 'data/time_series'\n",
    "\n",
    "df_sent.to_csv(save_path(relative_path, file_name), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter filename here:\n",
    "file_name = 'combined_df_sentiment.csv'\n",
    "# Enter relative path for saving the file:\n",
    "relative_path = 'data/model_input'\n",
    "\n",
    "combined_df.to_csv(save_path(relative_path, file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
