{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import scienceplots\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "REPO_PATH = os.getenv(\"REPO_PATH\")\n",
    "\n",
    "# Import main utility functions\n",
    "sys.path.insert(0, rf'{REPO_PATH}src_HF')\n",
    "plt.style.use('science')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUTURES = ['CLc1', 'LCOc1']\n",
    "TOPICS = ['CRU', 'CWP', 'CEN']\n",
    "\n",
    "dfs = {\n",
    "    future: pd.read_csv(\n",
    "        os.path.join(\n",
    "            REPO_PATH,\n",
    "            'data',\n",
    "            'prepared_data',\n",
    "            f\"{future}_5min_resampled.csv\"\n",
    "        ),\n",
    "        index_col='date',\n",
    "        parse_dates=True\n",
    "    ) for future in FUTURES\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5), dpi=200)\n",
    "\n",
    "df = dfs['CLc1']\n",
    "\n",
    "display(df.columns)\n",
    "\n",
    "plot = ['CRU_TextBlob_SI', 'CRU_VADER_SI']\n",
    "\n",
    "for i, topic in enumerate(plot):\n",
    "    df[topic].plot(ax=ax, label=topic)\n",
    "\n",
    "ax.grid(alpha=0.2)\n",
    "ax.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple linear regression\n",
    "# X = df[df.filter(like='_SI').columns]\n",
    "X = df.drop(columns=['TARGET_1'])\n",
    "\n",
    "y = df['TARGET_1']\n",
    "\n",
    "X_const = sm.add_constant(X)\n",
    "model = sm.OLS(y, X_const).fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO and Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scale variables\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "lamdas = np.logspace(-2, 5, 500)\n",
    "\n",
    "coefs_lasso = []\n",
    "CV_MSE_lasso = []\n",
    "\n",
    "coefs_ridge = []\n",
    "CV_MSE_ridge = []\n",
    "\n",
    "for i in tqdm(lamdas, desc='Fitting Lasso and Ridge'):\n",
    "    lasso = Lasso(alpha=i, max_iter=10000)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs_lasso.append(lasso.coef_)\n",
    "    CV_MSE_lasso.append(mean_squared_error(y_test, lasso.predict(X_test)))\n",
    "\n",
    "    ridge = Ridge(alpha=i, max_iter=10000)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coefs_ridge.append(ridge.coef_)\n",
    "    CV_MSE_ridge.append(mean_squared_error(y_test, ridge.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5), dpi=200)\n",
    "\n",
    "\n",
    "plot_y = [coefs_lasso, CV_MSE_lasso, coefs_ridge, CV_MSE_ridge]\n",
    "label_y = ['Mean Square Error', 'Coefficients']\n",
    "vlines = [CV_MSE_lasso, CV_MSE_ridge]\n",
    "\n",
    "# get twilight colors\n",
    "colormap = cm.get_cmap('twilight_r', 20)\n",
    "\n",
    "# Set the color cycle to the twilight colormap\n",
    "axs[0].set_prop_cycle(color=colormap(np.linspace(0, 1, 8)))\n",
    "axs[1].set_prop_cycle(color=colormap(np.linspace(0, 1, 2)))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax.plot(lamdas, plot_y[i], color='black' if i == 1 else None, lw=1.2)\n",
    "    ax.set_xscale('log')\n",
    "    # adjust tick size\n",
    "    ax.tick_params(axis='both', which='major', labelsize=13)\n",
    "    ax.set_xlabel('$\\lambda$', fontsize=15)\n",
    "    ax.set_ylabel(label_y[1] if i % 2 == 0 else label_y[0], fontsize=15)\n",
    "    ax.axvline(\n",
    "        lamdas[np.argmin(vlines[0] if i < 2 else vlines[1])], \n",
    "        color='red', \n",
    "        linestyle='-.',\n",
    "        lw=1\n",
    "    )\n",
    "\n",
    "# set color on axs[1] line\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('LASSO_Results.png')\n",
    "\n",
    "# get coefficients for the best lambda\n",
    "lasso = Lasso(alpha=lamdas[np.argmin(CV_MSE_lasso)], max_iter=10000)\n",
    "lasso.fit(X_train, y_train)\n",
    "print('Intercept for the best lambda:', lasso.intercept_)\n",
    "print('MSE for the best lambda:', mean_squared_error(y_test, lasso.predict(X_test)))\n",
    "\n",
    "# get coefficients for the best lambda\n",
    "ridge = Lasso(alpha=lamdas[np.argmin(CV_MSE_ridge)], max_iter=10000)\n",
    "ridge.fit(X_train, y_train)\n",
    "print('Intercept for the best lambda:', ridge.intercept_)\n",
    "print('MSE for the best lambda:', mean_squared_error(y_test, ridge.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(lasso.coef_, X.columns, columns=['Coefficients']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 500\n",
    "\n",
    "# plot test results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5), dpi=200)\n",
    "\n",
    "y_test[-window:].plot(ax=ax, label='True', lw=0.9)\n",
    "# pd.Series(lasso.predict(X_test), index=y_test.index)[-window:].plot(ax=ax, label='Lasso', lw=0.9)\n",
    "\n",
    "\n",
    "# predict with lasso and backword elimination\n",
    "# get the best lambda\n",
    "lasso = Lasso(alpha=lamdas[np.argmin(CV_MSE_lasso)], max_iter=10000)\n",
    "lasso.fit(X_train, y_train)\n",
    "# get the best features\n",
    "features = X.columns[lasso.coef_ != 0]\n",
    "X_train_BE = X_train[features]\n",
    "X_test_BE = X_test[features]\n",
    "# fit the model\n",
    "lasso = Lasso(alpha=lamdas[np.argmin(CV_MSE_lasso)], max_iter=10000)\n",
    "lasso.fit(X_train_BE, y_train)\n",
    "# plot\n",
    "pd.Series(lasso.predict(X_test_BE), index=y_test.index)[-window:].plot(ax=ax, label='Lasso BE', lw=0.9)\n",
    "\n",
    "# number of variables in reduced model vs original\n",
    "print('Number of variables in reduced model:', len(features))\n",
    "print('Number of variables in original model:', len(X.columns))\n",
    "\n",
    "# predict with normal OLS\n",
    "X_const = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_const).fit()\n",
    "X_const = sm.add_constant(X_test)\n",
    "y_pred = model.predict(X_const)\n",
    "pd.Series(y_pred, index=y_test.index)[-window:].plot(ax=ax, label='OLS', lw=0.9)\n",
    "# calculate mse\n",
    "print('MSE OLS:', mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# predict with XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train_BE, y_train)\n",
    "pd.Series(xgb.predict(X_test_BE), index=y_test.index)[-window:].plot(ax=ax, label='XGBoost', lw=0.6)\n",
    "# calculate mse\n",
    "print('MSE XGBoost:', mean_squared_error(y_test, xgb.predict(X_test_BE)))\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "\n",
    "# sgb feature importance\n",
    "from xgboost import plot_importance\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5), dpi=200)\n",
    "\n",
    "# only show top 10 features\n",
    "plot_importance(xgb, ax=ax, max_num_features=20)\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "ax.grid(alpha=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
