{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "REPO_PATH =  os.getenv('REPO_PATH')\n",
    "plt.style.use('science')\n",
    "\n",
    "sys.path.insert(0, rf'{REPO_PATH}src_HF')\n",
    "from utils.text_utils import clean_token_series, create_wordcloud, IGNORE_WORDS\n",
    "from utils.sentiment_utils import add_textblob_polarity, add_vader_compound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = 'CRU'\n",
    "\n",
    "text_df = pd.read_json(\n",
    "    rf'{REPO_PATH}data\\news_data\\EIKON_{TOPIC}_NEWS_COMPLETE.json', \n",
    "    lines=True, \n",
    "    orient='records'\n",
    ")\n",
    "\n",
    "text_df['tokenized'], text_df['tokenized_cleaned'] = clean_token_series(text_df['fullStory'])\n",
    "\n",
    "display(text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a word dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_series = text_df['tokenized_cleaned'].explode()\n",
    "\n",
    "word_series = word_series[~word_series.isin(IGNORE_WORDS)]\n",
    "\n",
    "word_df = pd.DataFrame(\n",
    "    word_series.value_counts()\n",
    ").reset_index().rename(columns={'tokenized_cleaned': 'word'})\n",
    "\n",
    "word_df['vader'] = add_vader_compound(word_df['word'])\n",
    "word_df['textblob'] = add_textblob_polarity(word_df['word'])\n",
    "\n",
    "display(word_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_ID = 'textblob'\n",
    "\n",
    "conditions = [\n",
    "    word_df[SENTIMENT_ID] < -0.5,\n",
    "    (word_df[SENTIMENT_ID] < -0.0) & (word_df[SENTIMENT_ID] > -0.5),\n",
    "    (word_df[SENTIMENT_ID] > 0.0) & (word_df[SENTIMENT_ID] < 0.5),\n",
    "    word_df[SENTIMENT_ID] > 0.5,\n",
    "]\n",
    "\n",
    "condition_names = [\n",
    "    'Negative sentiment',\n",
    "    'Slightly Negative sentiment',\n",
    "    'Slightly Positive sentiment',\n",
    "    'Positive sentiment'\n",
    "]\n",
    "\n",
    "N = len(word_df)\n",
    "\n",
    "n = len(word_df[word_df[SENTIMENT_ID] == 0.0][\"word\"])\n",
    "print(f'Neutral sentiment: {n}, ({n/N:.2%})')\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, facecolor=None, figsize=(12, 4), dpi=200)\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "\n",
    "    filtered_word_series = word_df[conditions[i]]['word']\n",
    "    n = len(filtered_word_series)\n",
    "    print(f'{condition_names[i]}: {n}, ({n/N:.2%})')\n",
    "    wordcloud = create_wordcloud(filtered_word_series, height=700)\n",
    "    ax.imshow(wordcloud, interpolation='bilinear')\n",
    "    # ax.set_title(f'{condition_names[i]}', fontsize=19, loc='left', y=1.05)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=0)\n",
    "\n",
    "fig.savefig(rf'images\\{SENTIMENT_ID}_{TOPIC}_word_sentiment_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df['word_count'] = 1\n",
    "\n",
    "# sum word_count where both sia and textblob are the same\n",
    "word_df_grouped = word_df.groupby(['vader', 'textblob']).sum().reset_index()\n",
    "\n",
    "# remove row where both values are 0\n",
    "word_df_grouped = word_df_grouped[(word_df_grouped['vader'] != 0) | (word_df_grouped['textblob'] != 0)]\n",
    "\n",
    "word_df_grouped\n",
    "fig = word_df_grouped.plot.scatter(\n",
    "    x='vader', \n",
    "    y='textblob', \n",
    "    figsize=(10, 7), \n",
    "    c='word_count', \n",
    "    s='word_count', \n",
    "    colormap='twilight_shifted',\n",
    ")\n",
    "\n",
    "# increase label sizes\n",
    "fig.set_xlabel('VADER', fontsize=15)\n",
    "fig.set_ylabel('TextBlob', fontsize=15)\n",
    "fig.tick_params(axis='both', which='major', labelsize=12)\n",
    "fig.grid(alpha=0.3)\n",
    "\n",
    "\n",
    "cbar = fig.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "cbar.set_label('Word count', fontsize=15)\n",
    "\n",
    "fig.figure.savefig(r'images\\sentiment_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headline and story length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['tokenized_h'], text_df['tokenized_cleaned_h'] = clean_token_series(text_df['text'])\n",
    "\n",
    "# remove punctuation from tokenized_h and tokenized\n",
    "text_df['tokenized_h_words'] = text_df['tokenized_h'].apply(lambda x: [word for word in x if word.isalnum()])\n",
    "text_df['tokenized_words'] = text_df['tokenized'].apply(lambda x: [word for word in x if word.isalnum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_headline = text_df['tokenized_h_words'].apply(len)\n",
    "word_counts_story = text_df['tokenized_words'].apply(len)\n",
    "\n",
    "# set limits\n",
    "word_counts_headline = word_counts_headline[word_counts_headline < 80]\n",
    "word_counts_story = word_counts_story[word_counts_story < 1500]\n",
    "\n",
    "wc_df = pd.DataFrame({\n",
    "    'headline': word_counts_headline,\n",
    "    'story': word_counts_story\n",
    "})\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), dpi=200)\n",
    "\n",
    "colormap = plt.cm.get_cmap('twilight', 256)\n",
    "palette = [colormap(i) for i in (70, 180)]\n",
    "\n",
    "wc_df['headline'].plot(\n",
    "    kind='hist', \n",
    "    bins=75, \n",
    "    color=palette[0],\n",
    "    edgecolor='black',\n",
    "    ax=ax1,\n",
    "    )\n",
    "\n",
    "wc_df['story'].plot(\n",
    "    kind='hist', \n",
    "    bins=75, \n",
    "    color=palette[1],\n",
    "    edgecolor='black',\n",
    "    ax=ax2,\n",
    "    )\n",
    "\n",
    "for ax, label in zip((ax1, ax2), ('Headline ', 'Full text ')):\n",
    "    ax.set_xlabel(label + 'word count', fontsize=13)\n",
    "    ax.set_ylabel('Frequency', fontsize=13)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "fig.figure.savefig(f'images/news_word_count_dist.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
