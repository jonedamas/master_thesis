{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(input_str: str) -> datetime:\n",
    "    date_str = input_str.replace(\"Published \\n \\n \", \"\").replace(\" GMT\\n\", \"\").strip()\n",
    "    date_time_obj = datetime.strptime(date_str, \"%d %B %Y %H:%M\")\n",
    "\n",
    "    return date_time_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 0\n",
    "article_archive = {}\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    url = f'https://www.upstreamonline.com/archive?offset={i + 1}0&publishdate=01.01.2014-31.12.2023'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f'Failed to fetch page {url}')\n",
    "        pass\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    articles = soup.find_all('a', class_='card-link text-reset') # Find all articles\n",
    "    publish_dates = soup.find_all('span', class_='published-at') # Find all publish dates\n",
    "\n",
    "    for i, a in enumerate(articles):\n",
    "        date = publish_dates[i].text[14:-5]\n",
    "        \n",
    "        link = 'https://www.upstreamonline.com' + a.get('href')\n",
    "        text = a.text[3:]\n",
    "\n",
    "        article_archive[ID] = [date, text, link]\n",
    "        ID += 1\n",
    "\n",
    "    time.sleep(0.1)  # Sleep to be respectful to the server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(article_archive, index=['DATE', 'HEADLINE', 'LINK']).T\n",
    "\n",
    "df['DATETIME'] = df['DATE'].apply(clean_date)\n",
    "\n",
    "display(df)\n",
    "\n",
    "# save as csv\n",
    "df.to_csv('data/upstreamonline.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "tokenized = df['HEADLINE'].apply(sent_tokenize)\n",
    "\n",
    "# Tokenize the headlines\n",
    "tokenized = tokenized.apply(lambda x: [word_tokenize(s) for s in x])\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenized = tokenized.apply(lambda x: [[w for w in s if w.lower() not in stop_words] for s in x][0])\n",
    "\n",
    "# sentiment analysis\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "print(tokenized)\n",
    "\n",
    "sentiments = tokenized.apply(lambda x: [sia.polarity_scores(s) for s in x])\n",
    "sentiments = sentiments.apply(lambda x: [s['compound'] for s in x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SENTIMENT'] = sentiments.apply(sum)\n",
    "df.set_index('DATETIME', inplace=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# group by date and calculate the mean sentiment\n",
    "df_sent = df.resample('D').mean()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "df_crude = yf.download('CL=F', start='2019-09-18', end='2023-12-31')[['Adj Close']]\n",
    "\n",
    "\n",
    "df_sent['SENTIMENT'].ewm(alpha=0.05).mean().plot(kind='line', ax=ax1, title='Sentiment of UpstreamOnline headlines', label='Sentiment Index')\n",
    "df_crude['Adj Close'].plot(kind='line', color='r', ax=ax2, label='Crude Oil price')\n",
    "\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "ax1.set_ylabel('Sentiment')\n",
    "ax2.set_ylabel('Crude Oil price')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
