{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "REPO_PATH =  os.getenv('REPO_PATH')\n",
    "plt.style.use('science')\n",
    "\n",
    "sys.path.insert(0, rf'{REPO_PATH}src')\n",
    "from utils.main_utils import combload_topic_dfs\n",
    "from utils.text_utils import clean_token_series, create_word_df, create_wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = ['CRU', 'CWP', 'CEN']\n",
    "\n",
    "text_df = combload_topic_dfs(\n",
    "    TOPICS,\n",
    "    lambda topic: rf'{REPO_PATH}data\\news_data\\EIKON_{topic}_NEWS_COMPLETE.json', \n",
    ")\n",
    "\n",
    "text_df['tokenized'], text_df['tokenized_cleaned'] = clean_token_series(\n",
    "    text_df['fullStory'], \n",
    "    include_raw=True\n",
    ")\n",
    "\n",
    "# Create word dataframes with sentiment\n",
    "word_dfs = {topic: create_word_df(text_df, topic) for topic in TOPICS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_sent_wd(\n",
    "        df: pd.DataFrame,\n",
    "        topic: str,\n",
    "        analyzer: str,\n",
    "        conditions: list,\n",
    "    ) -> plt.Figure:\n",
    "\n",
    "    title = {\n",
    "        'vader': 'VADER',\n",
    "        'textblob': 'TextBlob'\n",
    "    }\n",
    "\n",
    "    cond_names = [\n",
    "            'Negative sentiment',\n",
    "            'Neutral sentiment',\n",
    "            'Positive sentiment'\n",
    "    ]\n",
    "\n",
    "    N = len(df)\n",
    "    n = len(df[df[analyzer] == 0.0][\"word\"])\n",
    "    print(f'{topic} - {title[analyzer]}')\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, facecolor=None, figsize=(12, 4), dpi=200)\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        filtered_word_series = df[conditions[i]]['word']\n",
    "        n = len(filtered_word_series)\n",
    "        print(f'{cond_names[i]}: {n}, ({n/N:.2%})')\n",
    "        wordcloud = create_wordcloud(filtered_word_series, height=400)\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.set_title(f'{cond_names[i]}', y=-0.15, fontsize=19, loc='center')\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    print()\n",
    "    fig.text(\n",
    "            0.00, 1.08, f'{topic} - {title[analyzer]}', fontsize=22,\n",
    "            color='darkslategrey', transform=axs[0].transAxes\n",
    "        )\n",
    "    fig.tight_layout(pad=3)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "for analyzer in ['vader', 'textblob']:\n",
    "    for topic in TOPICS:\n",
    "        df = word_dfs[topic]\n",
    "\n",
    "        conditions = [\n",
    "            df[analyzer] < -0.25,\n",
    "            (df[analyzer] > -0.25) & (df[analyzer] < 0.25),\n",
    "            df[analyzer] > 0.25,\n",
    "        ]\n",
    "\n",
    "        fig = create_sent_wd(df, topic, analyzer, conditions)\n",
    "\n",
    "        fig.savefig(rf'images\\{analyzer}_{topic}_word_sentiment_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = pd.concat(word_dfs.values(), ignore_index=True)\n",
    "\n",
    "comb_df['word_count'] = 1\n",
    "\n",
    "# sum word_count where both sia and textblob are the same\n",
    "word_df_grouped = comb_df.groupby(\n",
    "    ['vader', 'textblob']\n",
    ").sum().reset_index()\n",
    "\n",
    "# remove row where both values are 0\n",
    "word_df_grouped = word_df_grouped[\n",
    "    (word_df_grouped['vader'] != 0) | (word_df_grouped['textblob'] != 0)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(word_df_grouped)\n",
    "\n",
    "fig = word_df_grouped.plot.scatter(\n",
    "    x='vader', \n",
    "    y='textblob', \n",
    "    figsize=(10, 7), \n",
    "    c='word_count',\n",
    "    s='word_count', \n",
    "    colormap='twilight_shifted',\n",
    ")\n",
    "\n",
    "# increase label sizes\n",
    "fig.set_xlabel('VADER', fontsize=15)\n",
    "fig.set_ylabel('TextBlob', fontsize=15)\n",
    "fig.tick_params(axis='both', which='major', labelsize=12)\n",
    "fig.grid(alpha=0.3)\n",
    "\n",
    "\n",
    "cbar = fig.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "cbar.set_label('Word count', fontsize=15)\n",
    "\n",
    "fig.figure.savefig('images\\sentiment_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headline and story length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['tokenized_h'], text_df['tokenized_cleaned_h'] = clean_token_series(\n",
    "    text_df['text'], \n",
    "    include_raw=True\n",
    ")\n",
    "\n",
    "# remove punctuation from tokenized_h and tokenized\n",
    "text_df['tokenized_h_words'] = text_df['tokenized_h'].apply(\n",
    "    lambda x: [word for word in x if word.isalnum()]\n",
    ")\n",
    "text_df['tokenized_words'] = text_df['tokenized'].apply(\n",
    "    lambda x: [word for word in x if word.isalnum()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_headline = text_df['tokenized_h_words'].apply(len)\n",
    "word_counts_story = text_df['tokenized_words'].apply(len)\n",
    "\n",
    "wc_df = pd.DataFrame({\n",
    "    'headline': word_counts_headline,\n",
    "    'story': word_counts_story\n",
    "})\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), dpi=200)\n",
    "\n",
    "colormap = plt.cm.get_cmap('twilight', 256)\n",
    "palette = [colormap(i) for i in (70, 180)]\n",
    "\n",
    "wc_df['headline'][wc_df['headline'] < 100].plot(\n",
    "    kind='hist', \n",
    "    bins=75, \n",
    "    color=palette[0],\n",
    "    edgecolor='black',\n",
    "    ax=ax1,\n",
    "    )\n",
    "\n",
    "wc_df['story'][wc_df['story'] < 3000].plot(\n",
    "    kind='hist', \n",
    "    bins=75, \n",
    "    color=palette[1],\n",
    "    edgecolor='black',\n",
    "    ax=ax2,\n",
    "    )\n",
    "\n",
    "for ax, label in zip((ax1, ax2), ('Headline ', 'Full text ')):\n",
    "    ax.set_xlabel(label + 'word count', fontsize=13)\n",
    "    ax.set_ylabel('Frequency', fontsize=13)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "fig.figure.savefig(f'images/news_word_count_dist.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
