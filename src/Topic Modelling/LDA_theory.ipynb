{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K: int = 2  # Topics are sport and astronomy\n",
    "\n",
    "vocabulary: dict = {\n",
    "    'ball': 0,\n",
    "    'planet': 1,\n",
    "    'star': 2,\n",
    "    'tennis': 3,\n",
    "    'basketball': 4,\n",
    "    'football': 5,\n",
    "    'sun': 6,\n",
    "    'moon': 7,\n",
    "    'earth': 8,\n",
    "    'run': 9\n",
    "}\n",
    "\n",
    "V: int = len(vocabulary)  # Number of words in the vocabulary\n",
    "\n",
    "documents: list = [\n",
    "    ['ball', 'tennis', 'basketball', 'football', 'star'],\n",
    "    ['planet', 'star', 'sun', 'moon', 'earth', 'ball'],\n",
    "    ['ball', 'tennis', 'basketball', 'planet', 'football'],\n",
    "    ['star', 'sun', 'moon', 'earth', 'ball', 'run'],\n",
    "    ['ball', 'tennis', 'basketball', 'planet', 'earth']\n",
    "]\n",
    "\n",
    "M: int = len(documents)  # Number of documents\n",
    "\n",
    "N: int = sum([len(doc) for doc in documents]) # Total number of words in all documents\n",
    "\n",
    "alpha = np.array([1, 1])  # Dirichlet prior for document-topic distribution\n",
    "\n",
    "beta = np.array([0.01 for i in range(len(vocabulary))])  # Dirichlet prior for topic-word distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "Algorithm\n",
    "\n",
    "\t1. Choose θ_i  ~ Dir(α), where i∈{1,…,M} and Dir(α) is a Dirichlet distribution with a symetric parameter α which typically is sparse (α<1)\n",
    "\n",
    "\t2. Choose ϕ_k  ~ Dir(β), where k∈{1,…,K} and β typically is sparse\n",
    "\n",
    "\t3. For each of the word positions i,j, where i∈{1,…,M}, and j∈{1,…,N_i }\n",
    "\t\n",
    "\t\ta. Choose a topic z_(i,j)  ~ Multinomial(θ_i)\n",
    "\t\t\n",
    "\t\tb. Choose a topic w_(i,j)  ~ Multinomial(ϕ_(z_(i,j) ))\n",
    "\n",
    "Note that multinomial distribution here refers to the multinomial with only one trial, which is also known as the categorical distribution.\n",
    "\n",
    "'''\n",
    "\n",
    "def lda():\n",
    "    theta = np.random.dirichlet(alpha, M)\n",
    "    phi = np.random.dirichlet(beta, K)\n",
    "\n",
    "    z = np.zeros((M, max([len(doc) for doc in documents])), dtype=int)\n",
    "    w = np.zeros((M, max([len(doc) for doc in documents])), dtype=int)\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        for j, word in enumerate(doc):\n",
    "            z[i, j] = np.random.choice(K, p=theta[i])\n",
    "            w[i, j] = np.random.choice(V, p=phi[z[i, j]])\n",
    "\n",
    "    return theta, phi, z, w\n",
    "\n",
    "theta, phi, z, w = lda()\n",
    "\n",
    "# go through the documents and print the words and their topics\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Document {i + 1}:\")\n",
    "    for j, word in enumerate(doc):\n",
    "        print(f\"Word: {word}, Topic: {z[i, j]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
