{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "pyLDAvis.enable_notebook()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "REPO_PATH =  os.getenv('REPO_PATH')\n",
    "\n",
    "sys.path.insert(0, rf'{REPO_PATH}src')\n",
    "from utils.text_utils import clean_token_series, IGNORE_WORDS\n",
    "from utils.topic_utils import classify_article, LDAModelSetup\n",
    "from utils.main_utils import combload_topic_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS: list[str] = ['CRU', 'CWP', 'CEN']\n",
    "\n",
    "text_df = combload_topic_dfs(\n",
    "    TOPICS,\n",
    "    lambda topic: rf'{REPO_PATH}data\\news_data\\EIKON_{topic}_NEWS_COMPLETE.json'\n",
    ")\n",
    "\n",
    "text_df['cleaned_tokenized'] = clean_token_series(text_df['fullStory'])\n",
    "\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA) model setup for subtopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_params: dict[str, int] = {\n",
    "    'num_topics': 3,\n",
    "    'chunksize': 500,\n",
    "    'passes': 20,\n",
    "    'iterations': 100,\n",
    "    'eval_every': 1\n",
    "}\n",
    "\n",
    "models = {}\n",
    "for topic in TOPICS:\n",
    "    model = LDAModelSetup(\n",
    "        text_df.loc[text_df['topic'] == topic, 'cleaned_tokenized'],\n",
    "        name=topic,\n",
    "        stopwords=IGNORE_WORDS, \n",
    "        lda_params=lda_params\n",
    "    )\n",
    "\n",
    "    models[topic] = model\n",
    "\n",
    "for topic, model in models.items():\n",
    "    print(f'Creating model for {topic}...')\n",
    "    model.generate_model()\n",
    "    model.generate_pyLDAvis()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDAvis visualization of gensim LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = 'CEN'\n",
    "\n",
    "display(models[TOPIC].visfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), dpi=200)\n",
    "\n",
    "for i, topic in enumerate(TOPICS):\n",
    "    models[topic].plot_pyLDAvis(axs[i])\n",
    "\n",
    "fig.tight_layout(pad=1)\n",
    "\n",
    "fig.savefig(rf'images\\pyLDAvis_topic_PC.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA setup for cross-topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_params: dict[str, int] = {\n",
    "    'num_topics': 5,\n",
    "    'chunksize': 1000,\n",
    "    'passes': 30,\n",
    "    'iterations': 500,\n",
    "    'eval_every': 1\n",
    "}\n",
    "\n",
    "full_model = LDAModelSetup(\n",
    "    text_df['cleaned_tokenized'],\n",
    "    name='All topics',\n",
    "    stopwords=IGNORE_WORDS, \n",
    "    lda_params=lda_params\n",
    ")\n",
    "\n",
    "full_model.generate_model()\n",
    "full_model.generate_pyLDAvis()\n",
    "\n",
    "display(full_model.visfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df = text_df.copy()\n",
    "df['crosstopic'] = df.progress_apply(\n",
    "    lambda x: classify_article(\n",
    "        x, \n",
    "        full_model.dictionary, \n",
    "        full_model.model\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names: dict[int, str] = {\n",
    "    0: 'Geopolitical Conflicts',\n",
    "    1: 'Interest Rates and Economic Policy',\n",
    "    2: 'Oil and Gas Production',\n",
    "    3: 'Banking and Finance',\n",
    "    4: 'Securities and Commodity Markets'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(16, 3), dpi=200)\n",
    "\n",
    "colors = sns.color_palette('twilight', n_colors=3)\n",
    "order = []\n",
    "\n",
    "size_df = df['crosstopic'].value_counts().sort_index()\n",
    "size_df = size_df.reindex(size_df.sort_values(ascending=False).index)\n",
    "\n",
    "for i, topic in enumerate(size_df.index.values):\n",
    "    # print topic size in %\n",
    "    values = df[df['crosstopic'] == topic]['topic'].value_counts().reindex(TOPICS)\n",
    "    values.plot.pie(ax=ax[i], colors=colors)\n",
    "\n",
    "    ax[i].set_ylabel('')\n",
    "    ax[i].set_title(r'$\\bf{Topic}$' + f' {i + 1}\\n{topic_names[i]}', fontsize=11)\n",
    "\n",
    "    # print top 10 words for each topic\n",
    "    top_words = full_model.model.show_topic(topic, topn=20)\n",
    "    words = [word for word, _ in top_words]\n",
    "    order.append(words)\n",
    "    print(f'Topic {i + 1}: {words}')\n",
    "\n",
    "fig.tight_layout(h_pad=1)\n",
    "\n",
    "fig.savefig(rf'images\\pyLDAvis_all_crosstopics.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA visualization of LDA model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7), dpi=200)\n",
    "\n",
    "full_model.plot_pyLDAvis(ax)\n",
    "\n",
    "fig.savefig(rf'images\\pyLDAvis_crosstopic_PCA.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign topics to each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for topic in TOPICS:\n",
    "    df_temp = text_df[text_df['topic'] == topic]\n",
    "    tqdm.pandas(desc=f\"Adding subtopics to {topic}\")\n",
    "    df_temp['topic'] = df_temp.progress_apply(\n",
    "        lambda x: classify_article(\n",
    "            x,\n",
    "            models[topic].dictionary, \n",
    "            models[topic].model\n",
    "        ), axis=1\n",
    "    )\n",
    "    topic_dict = dict(zip(df_temp['storyId'], df_temp['topic']))\n",
    "\n",
    "    with open(rf'{REPO_PATH}data\\topic_data\\{topic}_TOPICS.json', 'w') as f:\n",
    "        json.dump(topic_dict, f, indent=2)\n",
    "\n",
    "\n",
    "cross_topic_dict = dict(zip(df['storyId'], df['crosstopic']))\n",
    "\n",
    "with open(rf'{REPO_PATH}data\\topic_data\\CROSS_TOPICS.json', 'w') as f:\n",
    "        json.dump(cross_topic_dict, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
