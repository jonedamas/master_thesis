{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis.gensim\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "REPO_PATH =  os.getenv('REPO_PATH')\n",
    "sys.path.insert(0, rf'{REPO_PATH}src')\n",
    "\n",
    "from utils.text_utils import clean_token_series, IGNORE_WORDS\n",
    "from utils.topic_utils import classify_article, LDAModelSetup\n",
    "from utils.main_utils import combload_topic_dfs, apply_nb_style\n",
    "\n",
    "apply_nb_style()\n",
    "pyLDAvis.enable_notebook()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = ['CRU', 'CWP', 'CEN']\n",
    "\n",
    "text_df = combload_topic_dfs(\n",
    "    TOPICS,\n",
    "    lambda topic: rf'{REPO_PATH}data\\news_data\\EIKON_{topic}_NEWS_COMPLETE.json'\n",
    ")\n",
    "\n",
    "text_df['cleaned_tokenized'] = clean_token_series(text_df['fullStory'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA) model setup for subtopic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_PARAMS = {\n",
    "    'num_topics': 3,\n",
    "    'chunksize': 500,\n",
    "    'passes': 20,\n",
    "    'iterations': 100,\n",
    "    'eval_every': 1\n",
    "}\n",
    "\n",
    "models = {}\n",
    "for topic in TOPICS:\n",
    "    model = LDAModelSetup(\n",
    "        text_df.loc[text_df['topic'] == topic, 'cleaned_tokenized'],\n",
    "        name=topic,\n",
    "        stopwords=IGNORE_WORDS, \n",
    "        lda_params=LDA_PARAMS\n",
    "    )\n",
    "\n",
    "    models[topic] = model\n",
    "\n",
    "for topic, model in models.items():\n",
    "    print(f'Creating model for {topic}...')\n",
    "    model.generate_model()\n",
    "    model.generate_pyLDAvis()\n",
    "    model.print_top_words(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDAvis visualization of gensim LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = 'CRU'\n",
    "\n",
    "display(models[TOPIC].visfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRU_labels = {\n",
    "    0: 'Crude Oil Production and Prices',\n",
    "    1: 'Financial Markets and Economic Indicators',\n",
    "    2: 'Financial Instruments and Regulations'\n",
    "}\n",
    "\n",
    "CWP_labels = {\n",
    "    0: 'Middle East and Eastern Europe Conflicts',\n",
    "    1: 'International Security and Diplomacy',\n",
    "    2: 'Domestic Unrest and Government Actions'\n",
    "}\n",
    "\n",
    "CEN_labels = {\n",
    "    0: 'US Federal Reserve and Monetary Policy',\n",
    "    1: 'Economic Conditions and Government Policies',\n",
    "    2: 'Financial Markets and Global Banking'\n",
    "}\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), dpi=200)\n",
    "\n",
    "for i, topic in enumerate(TOPICS):\n",
    "    models[topic].plot_pyLDAvis(axs[i])\n",
    "\n",
    "fig.tight_layout(pad=1)\n",
    "\n",
    "fig.savefig(rf'images\\pyLDAvis_topic_PC.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA setup for cross-topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_PARAMS = {\n",
    "    'num_topics': 5,\n",
    "    'chunksize': 1000,\n",
    "    'passes': 30,\n",
    "    'iterations': 500,\n",
    "    'eval_every': 1\n",
    "}\n",
    "\n",
    "full_model = LDAModelSetup(\n",
    "    text_df['cleaned_tokenized'],\n",
    "    name='All topics',\n",
    "    stopwords=IGNORE_WORDS, \n",
    "    lda_params=LDA_PARAMS\n",
    ")\n",
    "\n",
    "full_model.generate_model()\n",
    "full_model.generate_pyLDAvis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-domain pyLDAvis visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_model.visfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc='Classifying articles with cross-domain topics')\n",
    "df = text_df.copy()\n",
    "df['crosstopic'] = df.progress_apply(\n",
    "    lambda x: classify_article(\n",
    "        x, \n",
    "        full_model.dictionary, \n",
    "        full_model.model\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = {\n",
    "    0: 'Securities and Commodity Markets',\n",
    "    1: 'Interest Rates and Economic Policy',\n",
    "    2: 'Geopolitical Conflicts',\n",
    "    3: 'Banking and Finance',\n",
    "    4: 'Oil and Gas Production'\n",
    "}\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=200)\n",
    "\n",
    "locs = [(0,0), (0,2), (0,4), (1,1), (1,3)]\n",
    "ax = [plt.subplot2grid((2,6), loc, colspan=2, fig=fig) for loc in locs]\n",
    "\n",
    "colors = sns.color_palette('twilight', n_colors=3)\n",
    "order = []\n",
    "\n",
    "size_df = df['crosstopic'].value_counts().sort_index()\n",
    "\n",
    "for i, topic in enumerate(size_df.index.values):\n",
    "    # print topic size in %\n",
    "    values = df[df['crosstopic'] == topic]['topic'].value_counts().reindex(TOPICS)\n",
    "    values.plot.pie(ax=ax[i], colors=colors)\n",
    "    topic_size = size_df[topic] / size_df.sum()\n",
    "    ax[i].set_ylabel('')\n",
    "    ax[i].set_title(\n",
    "        f'$\\\\mathbf{{Topic\\\\ {i + 1}}}$ | {topic_size:.0%}\\n{topic_names[i]}', \n",
    "        fontsize=11\n",
    "    )\n",
    "\n",
    "    # print top 10 words for each topic\n",
    "    top_words = full_model.model.show_topic(topic, topn=20)\n",
    "    words = [word for word, _ in top_words]\n",
    "    order.append(words)\n",
    "    print(f'Topic {i + 1}: {words}')\n",
    "\n",
    "fig.tight_layout(h_pad=0)\n",
    "\n",
    "fig.savefig(rf'images\\pyLDAvis_all_crosstopics.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA visualization of LDA model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7), dpi=200)\n",
    "\n",
    "full_model.plot_pyLDAvis(ax)\n",
    "\n",
    "fig.savefig(rf'images\\pyLDAvis_crosstopic_PCA.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign topics to each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in TOPICS:\n",
    "    df_temp = text_df[text_df['topic'] == topic]\n",
    "    tqdm.pandas(desc=f\"Adding subtopics to {topic}\")\n",
    "    df_temp['topic'] = df_temp.progress_apply(\n",
    "        lambda x: classify_article(\n",
    "            x,\n",
    "            models[topic].dictionary, \n",
    "            models[topic].model\n",
    "        ), axis=1\n",
    "    )\n",
    "    topic_dict = dict(zip(df_temp['storyId'], df_temp['topic']))\n",
    "\n",
    "    with open(rf'{REPO_PATH}data\\topic_data\\{topic}_TOPICS.json', 'w') as f:\n",
    "        json.dump(topic_dict, f, indent=2)\n",
    "\n",
    "\n",
    "cross_topic_dict = dict(zip(df['storyId'], df['crosstopic']))\n",
    "\n",
    "with open(rf'{REPO_PATH}data\\topic_data\\CROSS_TOPICS.json', 'w') as f:\n",
    "        json.dump(cross_topic_dict, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
