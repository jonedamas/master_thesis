{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pynytimes import NYTAPI\n",
    "import datetime as dt\n",
    "\n",
    "from tqdm.notebook import tnrange\n",
    "\n",
    "# Import utility functions\n",
    "sys.path.insert(0, r'c:\\Users\\joneh\\master_thesis\\src')\n",
    "from main_utils import *\n",
    "from db_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NY Times Developer Platform API\n",
    "\n",
    "\n",
    "**API Call limit:** API: 500 requests per day and 5 requests per minute. You should sleep 12 seconds between calls to avoid hitting the per minute rate limit. \n",
    "\n",
    "**Pagination:** The Article Search API returns a max of 10 results at a time. The meta node in the response contains the total number of matches (\"hits\") and the current offset. Use the page query parameter to paginate thru results (page=0 for results 1-10, page=1 for 11-20, ...). You can paginate thru up to 100 pages (1,000 results). If you get too many results try filtering by date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('API_keys/NYT_API_KEY.txt', 'r') as file:\n",
    "    API_KEY = file.read()\n",
    "\n",
    "nyt = NYTAPI(API_KEY, parse_dates=True)\n",
    "\n",
    "query = 'Crude AND Oil'\n",
    "\n",
    "year = 2003\n",
    "\n",
    "articles = nyt.article_search(\n",
    "    query=query,\n",
    "    results=10000,\n",
    "    dates={\n",
    "        'begin': dt.datetime(year, 1, 1), \n",
    "        'end': dt.datetime(year, 12, 31)\n",
    "    },\n",
    "    options={\n",
    "        'sort': 'newest'\n",
    "    }\n",
    ")\n",
    "\n",
    "display(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "\n",
    "for i in tnrange(len(articles)):\n",
    "    article = articles[i]\n",
    "    aritcle_id = article['_id']\n",
    "    pub_date = article['pub_date']\n",
    "    article_url = article['web_url']\n",
    "    headline = article['abstract']\n",
    "\n",
    "    res_list.append(\n",
    "        {'article_id': aritcle_id,\n",
    "         'headline': headline, \n",
    "         'datetime': pub_date, \n",
    "         'web_url': article_url, \n",
    "        }\n",
    "    )\n",
    "  \n",
    "df = pd.DataFrame(res_list)\n",
    "# Turn of the timezone\n",
    "df['datetime'] = df['datetime'].dt.tz_localize(None)\n",
    "\n",
    "# add source tag\n",
    "df['source'] = 'NYT'\n",
    "# add query tag\n",
    "df['query'] = query.replace(\" \", \"\")\n",
    "\n",
    "display(df)\n",
    "display(df.info())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter filename here:\n",
    "file_name = f'NYT_{query.replace(\" \", \"\")}_{year}.csv'\n",
    "# Enter relative path for saving the file:\n",
    "relative_path = 'data/news'\n",
    "\n",
    "df.to_csv(save_path(relative_path, file_name), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df('news', 'NYT_CrudeANDOil.csv')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "news_db_commit(df, 'news')\n",
    "\n",
    "db_info(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine csv files\n",
    "\n",
    "run_combiner = False\n",
    "\n",
    "if run_combiner:\n",
    "    df = load_df('news', 'NYT_CrudeANDOil_2004.csv')\n",
    "\n",
    "    for i in range(5, 24):\n",
    "\n",
    "        if i < 10:\n",
    "            i = f'0{i}'\n",
    "\n",
    "        df = pd.concat([df, load_df('news', f'NYT_CrudeANDOil_20{i}.csv')])\n",
    "\n",
    "    # Enter filename here:\n",
    "    file_name = f'NYT_CrudeANDOil.csv'\n",
    "    # Enter relative path for saving the file:\n",
    "    relative_path = 'data/news'\n",
    "\n",
    "    df.to_csv(save_path(relative_path, file_name), index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
